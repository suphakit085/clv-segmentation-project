{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ’° 05 - CLV Modeling\n",
                "\n",
                "**Week 4-5 Deliverable**: CLV Predictions with Multiple Models\n",
                "\n",
                "## Objectives\n",
                "1. Build probabilistic CLV models (BG/NBD, Gamma-Gamma)\n",
                "2. Train machine learning CLV models (Random Forest, XGBoost)\n",
                "3. Compare model performance\n",
                "4. Generate CLV predictions for all customers\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datetime import datetime, timedelta\n",
                "\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
                "from sklearn.linear_model import LinearRegression, Ridge\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "pd.set_option('display.max_columns', None)\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print('Libraries loaded!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data\n",
                "df = pd.read_csv('../data/processed/online_retail_clean.csv', parse_dates=['InvoiceDate'])\n",
                "feature_matrix = pd.read_csv('../data/features/feature_matrix.csv')\n",
                "\n",
                "print(f'Transactions: {len(df):,}')\n",
                "print(f'Customers: {len(feature_matrix):,}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Prepare Data for Probabilistic Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate RFM data for probabilistic models\n",
                "reference_date = df['InvoiceDate'].max() + timedelta(days=1)\n",
                "\n",
                "# Aggregate by customer\n",
                "rfm_data = df.groupby('CustomerID').agg({\n",
                "    'InvoiceDate': ['min', 'max', lambda x: x.nunique()],\n",
                "    'InvoiceNo': 'nunique',\n",
                "    'Revenue': ['sum', 'mean']\n",
                "})\n",
                "\n",
                "rfm_data.columns = ['first_purchase', 'last_purchase', 'purchase_days', 'frequency', 'monetary', 'avg_order_value']\n",
                "rfm_data = rfm_data.reset_index()\n",
                "\n",
                "# Calculate T (customer age) and recency\n",
                "rfm_data['T'] = (reference_date - rfm_data['first_purchase']).dt.days\n",
                "rfm_data['recency'] = (rfm_data['last_purchase'] - rfm_data['first_purchase']).dt.days\n",
                "\n",
                "# For repeat purchase models, frequency is repeat purchases (total - 1)\n",
                "rfm_data['frequency_model'] = rfm_data['frequency'] - 1\n",
                "\n",
                "# Filter customers with at least one repeat purchase\n",
                "rfm_repeat = rfm_data[rfm_data['frequency_model'] > 0].copy()\n",
                "\n",
                "print(f'Customers for probabilistic model: {len(rfm_repeat):,}')\n",
                "rfm_data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. BG/NBD Model (Simplified Implementation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simplified BG/NBD-like predictions\n",
                "# For full implementation, use the lifetimes library\n",
                "\n",
                "class SimpleBGNBD:\n",
                "    \"\"\"Simplified BG/NBD-like model for CLV prediction\"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.avg_frequency = None\n",
                "        self.avg_recency_ratio = None\n",
                "        \n",
                "    def fit(self, frequency, recency, T):\n",
                "        \"\"\"Fit the model\"\"\"\n",
                "        self.avg_frequency = frequency.mean()\n",
                "        self.avg_recency_ratio = (recency / T).mean()\n",
                "        return self\n",
                "    \n",
                "    def predict_purchases(self, frequency, recency, T, t):\n",
                "        \"\"\"Predict expected purchases in next t periods\"\"\"\n",
                "        # Simple heuristic: customers with higher frequency and recent activity buy more\n",
                "        recency_factor = 1 - (T - recency) / T  # Higher if more recent\n",
                "        frequency_rate = frequency / T * 365  # Annualized purchase rate\n",
                "        \n",
                "        expected_purchases = frequency_rate * (t / 365) * recency_factor\n",
                "        return np.maximum(expected_purchases, 0)\n",
                "    \n",
                "    def predict_alive(self, frequency, recency, T):\n",
                "        \"\"\"Predict probability customer is still active\"\"\"\n",
                "        # Simple decay model\n",
                "        days_since_purchase = T - recency\n",
                "        avg_gap = T / (frequency + 1)\n",
                "        \n",
                "        # Probability decreases as time since last purchase increases\n",
                "        prob_alive = np.exp(-days_since_purchase / (2 * avg_gap))\n",
                "        return np.clip(prob_alive, 0, 1)\n",
                "\n",
                "# Fit model\n",
                "bgnbd = SimpleBGNBD()\n",
                "bgnbd.fit(\n",
                "    rfm_repeat['frequency_model'].values,\n",
                "    rfm_repeat['recency'].values,\n",
                "    rfm_repeat['T'].values\n",
                ")\n",
                "\n",
                "# Predict future purchases (next 365 days)\n",
                "rfm_repeat['predicted_purchases_1y'] = bgnbd.predict_purchases(\n",
                "    rfm_repeat['frequency_model'].values,\n",
                "    rfm_repeat['recency'].values,\n",
                "    rfm_repeat['T'].values,\n",
                "    t=365\n",
                ")\n",
                "\n",
                "# Predict alive probability\n",
                "rfm_repeat['prob_alive'] = bgnbd.predict_alive(\n",
                "    rfm_repeat['frequency_model'].values,\n",
                "    rfm_repeat['recency'].values,\n",
                "    rfm_repeat['T'].values\n",
                ")\n",
                "\n",
                "print('BG/NBD predictions complete')\n",
                "rfm_repeat[['CustomerID', 'frequency_model', 'recency', 'T', 'predicted_purchases_1y', 'prob_alive']].head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Gamma-Gamma Model (Simplified)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleGammaGamma:\n",
                "    \"\"\"Simplified Gamma-Gamma model for monetary value prediction\"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.avg_monetary = None\n",
                "        \n",
                "    def fit(self, frequency, monetary):\n",
                "        \"\"\"Fit the model\"\"\"\n",
                "        self.avg_monetary = monetary.mean()\n",
                "        return self\n",
                "    \n",
                "    def predict_monetary(self, frequency, monetary):\n",
                "        \"\"\"Predict expected average order value\"\"\"\n",
                "        # Weight between individual average and population average\n",
                "        # More frequency = more weight on individual average\n",
                "        weight = frequency / (frequency + 1)\n",
                "        expected_monetary = weight * monetary + (1 - weight) * self.avg_monetary\n",
                "        return expected_monetary\n",
                "\n",
                "# Fit model\n",
                "gg = SimpleGammaGamma()\n",
                "gg.fit(\n",
                "    rfm_repeat['frequency_model'].values,\n",
                "    rfm_repeat['avg_order_value'].values\n",
                ")\n",
                "\n",
                "# Predict expected monetary value\n",
                "rfm_repeat['predicted_monetary'] = gg.predict_monetary(\n",
                "    rfm_repeat['frequency_model'].values,\n",
                "    rfm_repeat['avg_order_value'].values\n",
                ")\n",
                "\n",
                "print('Gamma-Gamma predictions complete')\n",
                "rfm_repeat[['CustomerID', 'avg_order_value', 'predicted_monetary']].head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Calculate Probabilistic CLV"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CLV = Expected Purchases Ã— Expected Monetary Value Ã— Discount Factor\n",
                "discount_rate = 0.10  # 10% annual discount rate\n",
                "time_horizon = 1  # 1 year\n",
                "\n",
                "rfm_repeat['CLV_probabilistic'] = (\n",
                "    rfm_repeat['predicted_purchases_1y'] * \n",
                "    rfm_repeat['predicted_monetary'] * \n",
                "    rfm_repeat['prob_alive'] *\n",
                "    (1 / (1 + discount_rate))\n",
                ")\n",
                "\n",
                "print('=== Probabilistic CLV Summary ===')\n",
                "print(rfm_repeat['CLV_probabilistic'].describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CLV Distribution\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# CLV histogram\n",
                "rfm_repeat['CLV_probabilistic'].clip(upper=2000).hist(bins=50, ax=axes[0], \n",
                "                                                        color='steelblue', edgecolor='white')\n",
                "axes[0].set_title('CLV Distribution (Probabilistic)', fontsize=12, fontweight='bold')\n",
                "axes[0].set_xlabel('CLV (Â£)')\n",
                "axes[0].set_ylabel('Customer Count')\n",
                "axes[0].axvline(rfm_repeat['CLV_probabilistic'].mean(), color='red', linestyle='--', \n",
                "                label=f'Mean: Â£{rfm_repeat[\"CLV_probabilistic\"].mean():,.0f}')\n",
                "axes[0].legend()\n",
                "\n",
                "# Box plot by segment (if available)\n",
                "rfm_repeat_with_segment = rfm_repeat.merge(feature_matrix[['CustomerID', 'Segment']], on='CustomerID')\n",
                "rfm_repeat_with_segment.boxplot(column='CLV_probabilistic', by='Segment', ax=axes[1], rot=45)\n",
                "axes[1].set_title('CLV by Segment', fontsize=12, fontweight='bold')\n",
                "axes[1].set_xlabel('')\n",
                "plt.suptitle('')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/clv_probabilistic.png', dpi=300)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Machine Learning CLV Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare features for ML\n",
                "# Target: Historical CLV (total monetary value)\n",
                "# This simulates predicting future CLV based on past behavior\n",
                "\n",
                "# Use feature matrix\n",
                "ml_features = feature_matrix.copy()\n",
                "\n",
                "# Define target\n",
                "ml_features['target_CLV'] = ml_features['Monetary']  # Historical value as proxy\n",
                "\n",
                "# Select features for modeling\n",
                "feature_cols = [\n",
                "    'Recency', 'Frequency',\n",
                "    'total_orders', 'total_quantity',\n",
                "    'avg_quantity', 'avg_revenue',\n",
                "    'customer_lifetime_days', 'unique_products'\n",
                "]\n",
                "\n",
                "# Filter to available columns\n",
                "feature_cols = [c for c in feature_cols if c in ml_features.columns]\n",
                "\n",
                "X = ml_features[feature_cols].fillna(0)\n",
                "y = ml_features['target_CLV']\n",
                "\n",
                "print(f'Features: {len(feature_cols)}')\n",
                "print(f'Samples: {len(X):,}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Scale features\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(f'Train size: {len(X_train):,}')\n",
                "print(f'Test size: {len(X_test):,}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define models\n",
                "models = {\n",
                "    'Linear Regression': LinearRegression(),\n",
                "    'Ridge Regression': Ridge(alpha=1.0),\n",
                "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
                "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
                "}\n",
                "\n",
                "# Train and evaluate models\n",
                "results = []\n",
                "\n",
                "for name, model in models.items():\n",
                "    print(f'Training {name}...')\n",
                "    \n",
                "    # Use scaled data for linear models\n",
                "    if 'Linear' in name or 'Ridge' in name:\n",
                "        model.fit(X_train_scaled, y_train)\n",
                "        y_pred = model.predict(X_test_scaled)\n",
                "    else:\n",
                "        model.fit(X_train, y_train)\n",
                "        y_pred = model.predict(X_test)\n",
                "    \n",
                "    # Calculate metrics\n",
                "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
                "    mae = mean_absolute_error(y_test, y_pred)\n",
                "    r2 = r2_score(y_test, y_pred)\n",
                "    \n",
                "    results.append({\n",
                "        'Model': name,\n",
                "        'RMSE': rmse,\n",
                "        'MAE': mae,\n",
                "        'R2': r2\n",
                "    })\n",
                "    \n",
                "    print(f'  RMSE: {rmse:,.2f}, MAE: {mae:,.2f}, RÂ²: {r2:.3f}')\n",
                "\n",
                "results_df = pd.DataFrame(results).sort_values('RMSE')\n",
                "results_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model comparison visualization\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "# RMSE\n",
                "results_df.plot(x='Model', y='RMSE', kind='barh', ax=axes[0], color='steelblue', legend=False)\n",
                "axes[0].set_title('RMSE (Lower is Better)', fontweight='bold')\n",
                "axes[0].set_xlabel('RMSE')\n",
                "\n",
                "# MAE\n",
                "results_df.plot(x='Model', y='MAE', kind='barh', ax=axes[1], color='seagreen', legend=False)\n",
                "axes[1].set_title('MAE (Lower is Better)', fontweight='bold')\n",
                "axes[1].set_xlabel('MAE')\n",
                "\n",
                "# R2\n",
                "results_df.plot(x='Model', y='R2', kind='barh', ax=axes[2], color='coral', legend=False)\n",
                "axes[2].set_title('RÂ² Score (Higher is Better)', fontweight='bold')\n",
                "axes[2].set_xlabel('RÂ²')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/model_comparison.png', dpi=300)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Best Model Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use Random Forest as best model\n",
                "best_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
                "best_model.fit(X_train, y_train)\n",
                "\n",
                "# Predictions\n",
                "y_pred_train = best_model.predict(X_train)\n",
                "y_pred_test = best_model.predict(X_test)\n",
                "\n",
                "# Feature importance\n",
                "importance = pd.DataFrame({\n",
                "    'Feature': feature_cols,\n",
                "    'Importance': best_model.feature_importances_\n",
                "}).sort_values('Importance', ascending=False)\n",
                "\n",
                "print('=== Feature Importance ===')\n",
                "importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance visualization\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "\n",
                "importance.plot(x='Feature', y='Importance', kind='barh', ax=ax, color='steelblue', legend=False)\n",
                "ax.set_title('Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
                "ax.set_xlabel('Importance')\n",
                "ax.invert_yaxis()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/feature_importance.png', dpi=300)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Actual vs Predicted plot\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Test set\n",
                "axes[0].scatter(y_test, y_pred_test, alpha=0.3, s=20)\n",
                "max_val = max(y_test.max(), y_pred_test.max())\n",
                "axes[0].plot([0, max_val], [0, max_val], 'r--', label='Perfect Prediction')\n",
                "axes[0].set_xlabel('Actual CLV')\n",
                "axes[0].set_ylabel('Predicted CLV')\n",
                "axes[0].set_title('Actual vs Predicted (Test Set)', fontweight='bold')\n",
                "axes[0].legend()\n",
                "\n",
                "# Residual distribution\n",
                "residuals = y_test - y_pred_test\n",
                "residuals.hist(bins=50, ax=axes[1], color='seagreen', edgecolor='white')\n",
                "axes[1].set_xlabel('Residual (Actual - Predicted)')\n",
                "axes[1].set_ylabel('Frequency')\n",
                "axes[1].set_title('Residual Distribution', fontweight='bold')\n",
                "axes[1].axvline(0, color='red', linestyle='--')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/actual_vs_predicted.png', dpi=300)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Generate CLV Predictions for All Customers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predict CLV for all customers\n",
                "X_all = ml_features[feature_cols].fillna(0)\n",
                "ml_features['CLV_ML'] = best_model.predict(X_all)\n",
                "\n",
                "# Combine with probabilistic CLV\n",
                "clv_results = ml_features[['CustomerID', 'Monetary', 'Segment', 'CLV_ML']].copy()\n",
                "\n",
                "# Merge probabilistic CLV\n",
                "prob_clv = rfm_repeat[['CustomerID', 'CLV_probabilistic', 'prob_alive', 'predicted_purchases_1y']]\n",
                "clv_results = clv_results.merge(prob_clv, on='CustomerID', how='left')\n",
                "\n",
                "# Fill missing probabilistic CLV with ML estimate\n",
                "clv_results['CLV_probabilistic'] = clv_results['CLV_probabilistic'].fillna(clv_results['CLV_ML'] * 0.5)\n",
                "clv_results['prob_alive'] = clv_results['prob_alive'].fillna(0.5)\n",
                "\n",
                "# Create ensemble CLV (average of both models)\n",
                "clv_results['CLV_ensemble'] = (clv_results['CLV_ML'] + clv_results['CLV_probabilistic']) / 2\n",
                "\n",
                "print(f'CLV predictions generated for {len(clv_results):,} customers')\n",
                "clv_results.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CLV summary by segment\n",
                "clv_by_segment = clv_results.groupby('Segment').agg({\n",
                "    'CustomerID': 'count',\n",
                "    'Monetary': 'sum',\n",
                "    'CLV_ML': ['mean', 'sum'],\n",
                "    'CLV_probabilistic': ['mean', 'sum'],\n",
                "    'CLV_ensemble': ['mean', 'sum']\n",
                "}).round(2)\n",
                "\n",
                "clv_by_segment.columns = ['Customers', 'Historical_Revenue', 'Avg_CLV_ML', 'Total_CLV_ML',\n",
                "                          'Avg_CLV_Prob', 'Total_CLV_Prob', 'Avg_CLV_Ensemble', 'Total_CLV_Ensemble']\n",
                "clv_by_segment = clv_by_segment.sort_values('Total_CLV_Ensemble', ascending=False)\n",
                "\n",
                "clv_by_segment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CLV visualization by segment\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Total CLV by segment\n",
                "clv_by_segment['Total_CLV_Ensemble'].plot(kind='barh', ax=axes[0], color='steelblue')\n",
                "axes[0].set_title('Total Predicted CLV by Segment', fontweight='bold')\n",
                "axes[0].set_xlabel('Total CLV (Â£)')\n",
                "\n",
                "# Average CLV by segment\n",
                "clv_by_segment['Avg_CLV_Ensemble'].plot(kind='barh', ax=axes[1], color='seagreen')\n",
                "axes[1].set_title('Average Predicted CLV by Segment', fontweight='bold')\n",
                "axes[1].set_xlabel('Average CLV (Â£)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/clv_by_segment.png', dpi=300)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Key Insights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('=' * 60)\n",
                "print('CLV MODELING - KEY INSIGHTS')\n",
                "print('=' * 60)\n",
                "\n",
                "print('\\nðŸ“Š Model Performance:')\n",
                "best = results_df.iloc[0]\n",
                "print(f'   Best Model: {best[\"Model\"]}')\n",
                "print(f'   RMSE: Â£{best[\"RMSE\"]:,.2f}')\n",
                "print(f'   MAE: Â£{best[\"MAE\"]:,.2f}')\n",
                "print(f'   RÂ²: {best[\"R2\"]:.3f}')\n",
                "\n",
                "print('\\nðŸ’° CLV Summary:')\n",
                "print(f'   Total Predicted CLV: Â£{clv_results[\"CLV_ensemble\"].sum():,.2f}')\n",
                "print(f'   Average CLV: Â£{clv_results[\"CLV_ensemble\"].mean():,.2f}')\n",
                "print(f'   Median CLV: Â£{clv_results[\"CLV_ensemble\"].median():,.2f}')\n",
                "\n",
                "print('\\nðŸŽ¯ Top Features for CLV:')\n",
                "for i, row in importance.head(5).iterrows():\n",
                "    print(f'   {row[\"Feature\"]}: {row[\"Importance\"]*100:.1f}%')\n",
                "\n",
                "print('\\nðŸ’Ž High-Value Segments:')\n",
                "for seg in clv_by_segment.head(3).index:\n",
                "    data = clv_by_segment.loc[seg]\n",
                "    print(f'   {seg}: Â£{data[\"Total_CLV_Ensemble\"]:,.0f} ({data[\"Customers\"]:,} customers)')\n",
                "\n",
                "print('\\n' + '=' * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Save CLV Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save CLV predictions\n",
                "clv_results.to_csv('../data/features/clv_predictions.csv', index=False)\n",
                "clv_by_segment.to_csv('../data/features/clv_by_segment.csv')\n",
                "results_df.to_csv('../data/features/model_comparison.csv', index=False)\n",
                "\n",
                "print('CLV results saved!')\n",
                "print('  - clv_predictions.csv')\n",
                "print('  - clv_by_segment.csv')\n",
                "print('  - model_comparison.csv')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "Continue to **Notebook 06 - Advanced Segmentation** to:\n",
                "- Apply K-Means clustering\n",
                "- Perform Hierarchical clustering\n",
                "- Create advanced customer segments"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.14.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
